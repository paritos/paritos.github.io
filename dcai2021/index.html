<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>DCAI2021 - 1st Data-Centric AI Workshop</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="css/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/main.css" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body id="page-top">
  <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand page-scroll" href="#page-top">DCAI 2021</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a class="page-scroll" href="#about">About</a>
                </li>
                <li>
                    <a class="page-scroll" href="#dates">Important Dates</a>
                </li>
                <li>
                    <a class="page-scroll" href="#call-for-papers">Call for Papers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#organizers">Organizers</a>
                </li>
                <li>
                    <a class="page-scroll" href="#program">Program</a>
                </li>
                <li>
                    <a class="page-scroll" href="#invited-talks">Talks</a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>

  <header>
    <div class="header-content">
        <div class="header-content-inner">
            <h1>1st Data-Centric AI Workshop (DCAI 2021)</h1>
            <hr>
            <p>
            	<a href="https://neurips.cc/Conferences/2021/" target="_blank"><b>At the 35th NeurIPS Conference</b></a><br><br>
                <span style="color: white;">
            	<b>Date:</b> 6 December 2021<br>
                <b>Time PT:</b> 6:00am-12:20am<br>
                <b>Time EST:</b> 9:00am-3:20pm<br>
                <b>Time CET:</b> 2:00pm-8:20pm<br>
		<b>Location:</b> Virtual
                </span>
			</p>
            <a href="#dates" class="btn btn-primary btn-xl page-scroll">Important Dates</a>
            <span style="width: 20px; display: inline-block;"></span>
            <a href="https://www.humancomputation.com/attend.html#registration" target="_blank" class="btn btn-warning btn-xl">Register</a>
            <span style="width: 20px; display: inline-block;"></span>
            <a href="#invited-talks" class="btn btn-success btn-xl page-scroll">Talks</a>
        </div>
    </div>
</header>

  <section id="about">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <p>
		    <p> It’s a common joke that 80 percent of machine learning is actually data cleaning, as though that were a lesser task. Our view is that if 80 percent of our work is data preparation, then ensuring data quality is the most important work of a machine learning team and therefore a vital research area.  If we want to build an active research community focused on Data Centric AI, we need to come together to define the core problems and create ways to measure progress. 

<p>Our workshop will begin to define the core problems of Data Centric AI. We consider some of those problems to be: data collection/generation, data labeling, data preprocess/augmentation, data quality evaluation, data debt, and data governance. Many of these areas are in a nascent stage, and we hope to further their development by knitting them together into a coherent whole. We will invite a carefully selected set of speakers, augment them with an open call, and further the coherence with community building and a crowd-driven summary produced at the event. We plan to leverage <a href="htt://deeplearning.ai" target="_blank">deeplearning.ai</a>, which has several hundred thousand participants, to seed this community.</p>

<p>We will seek to drive progress in addressing these core problems by promoting the creation of a set of benchmarks for data quality and data-related algorithms. We want to bring together all work that pushes forward this new view of data-centric AI, e.g. the initiatives developing at <a href="https://mlcommons.org/en/" target="_blank">MLCommons</a>, a non-profit that operates the MLPerf benchmarks that have become standard for AI chip speed [3], but also others including. We envision MLCommons as providing a framework and resources for the evolution of benchmarks in this space, and our workshop as showcasing the best innovations revealed by those benchmarks and providing a focus event for the community submitting to them.</p>

<p>A huge amount of innovation — in algorithms, ideas, principles, and tools — is needed to make data-centric AI development efficient and effective. We hope that this workshop will help spark that innovation.</p>

		    
		    </p>
                    <p>This workshop continues a series of <u><b>preceding workshops on related topics</b></u>:
                    <ul style="font-size: 150%">
			 <li><a href="http://eval.how/dew2020/index.html" target="_blank">Data Excellence</a> @ HCOMP</li>    
                        <li><a href="http://eval.how/aaai-2020/" target="_blank">Meta-Eval 2020</a> @ AAAI</li>
                        <li><a href="http://eval.how/aaai/" target="_blank">REAIS 2019</a> @ HCOMP</li>
                        <li><a href="https://sadworkshop.wordpress.com/" target="_blank">SAD 2019</a> @ TheWebConf (WWW)</li>
                        <li><a href="https://sadworkshop.wordpress.com/2018-edition/" target="_blank">SAD 2018</a> @ HCOMP</li>
                    </ul>
                    </p>

                     </p>
                </p>
            </div>
        </div>

    </div>
</section>

  <section id="dates">
    <div class="container">
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">Important Dates</h2>
                <hr class="primary">
            </div>
        </div>
    </div>
    <div class="container">
        <div class="row">
            <div class="col-lg-3 col-md-6 text-center">
                <div class="service-box">
                    <i class="fa fa-4x fa-upload wow bounceIn text-primary"></i>
                    <h3>Submission Deadline</h3>
                    <p class="text-muted">October 1, 2021</p>
                </div>
            </div>
            <div class="col-lg-3 col-md-6 text-center">
                <div class="service-box">
                    <i class="fa fa-4x fa-envelope wow bounceIn text-primary" data-wow-delay=".1s"></i>
                    <h3>Notification of acceptance</h3>
                    <p class="text-muted">October 18, 2021</p>
                </div>
            </div>
            <div class="col-lg-3 col-md-6 text-center">
                <div class="service-box">
                    <i class="fa fa-4x fa-camera-retro wow bounceIn text-primary" data-wow-delay=".2s"></i>
                    <h3>Final camera-ready papers due</h3>
                    <p class="text-muted">October 22, 2021</p>
                </div>
            </div>
            <div class="col-lg-3 col-md-6 text-center">
                <div class="service-box">
                    <i class="fa fa-4x fa-users wow bounceIn text-primary" data-wow-delay=".3s"></i>
                    <h3>Workshop</h3>
                    <p class="text-muted">
                        December 6, 2021<br>
                        PT: 6:00am-12:20am<br>
                        EST: 9:00am-3:20pm<br>
                        CET: 2:00pm-8:20pm
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

  <section class="bg-primary" id="call-for-papers">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2 class="section-heading text-center">Call for Papers</h2>
                <hr class="light">
                <p class="text-faded">
<p class="text-faded"><b><a href="https://mlcommons.org/en/" target="_blank" style="color:white;">MLCommons</a></b> accelerates machine learning innovation to benefit everyone. Machine learning has tremendous potential to save lives in areas like healthcare and automotive safety and to improve information access and understanding through technologies like voice interfaces, automatic translation, and natural language processing. However, machine learning is entirely unlike conventional software -- developers train an application rather than program it -- and requires a whole new set of techniques analogous to the breakthroughs in precision measurement, raw materials, and manufacturing that drove the industrial revolution. <b><a href="https://mlcommons.org/en/" target="_blank" style="color:white;">MLCommons</a></b> aims to answer the nascent machine learning industry's needs through open, collaborative engineering in three areas: benchmarks, datasets, and best practices. MLCommons Research (MLCR) explores research questions that advance ML innovation that benefits from MLCommons artifacts (benchmarks, datasets and best practices) and activities (working group meetings and other collaborations). During this inaugural year, MLCR is soliciting research proposals for groundbreaking research and engineering related to advancing the creation of open-source data sets. Specifically, MLCommons Research is interested in accelerating the development of open-source data sets via principled data engineering methods. </p>

<p class="text-faded">The ML community has a strong track record of building data sets. But this endeavor is often artisanal—painstaking and expensive. The community lacks high productivity and efficient open data engineering tools to make building data sets easier, cheaper and more repeatable. Constructing a data set today is akin to programming before the era of compilers, libraries and other tools. So, the challenge ML Commons puts forth is whether we can accelerate data-set creation by democratizing data engineering—that is, building computer systems (“architectures”) that can automatically produce training data cheaply and efficiently. Please refer to our <b><a href="https://arxiv.org/pdf/2102.11447.pdf" target="_blank" style="color:white;"></b>data engineering white paper</a> for more information. </p>

<p class="text-faded">Applicants should submit a plan outlining the impact their research is intended to produce, how the research area will gain from the work, a timeline for the project, and a budget summary of how to use the proposed funding. Proposals are strongly encouraged to concentrate on supporting Ph.D. students. Proposals from small collaborative teams are also strongly encouraged, especially with PIs that bridge machine learning from theory to practice.</p>

<p class="text-faded">MLCommons plans to award four to six four unrestricted gift awards, depending on criteria, up to $50,000 each. Awards are structured as unrestricted gifts to the principal investigator's academic institution or organization and as such, <b><a href="https://mlcommons.org/en/" target="_blank" style="color:white;">MLCommons</a><b> retains no intellectual property rights to the resulting work. Recipients are encouraged to publish outcomes and commit related code to open-source repositories. Recipients are assigned an MLCommons research contact who offers consultation and advice along with opportunities to participate in <b><a href="https://mlcommons.org/en/" target="_blank" style="color:white;">MLCommons</a></b> events and training sessions.</p>

<p class="text-faded">Our goal is to define the core problems and create ways to measure progress in Data Centric AI.  For this purpose we aim at a discussion-centric workshop schedule, which will allow good coverage of existing work through short-form presentations (5 min recorded lightning talks) and breakout sessions (mix of submitted/live questions for the speakers), which will be concluded with a group discussion and question answering session, summarized and published by a scribe. We believe this will help us expand the understanding of where we stand and what are future directions in the field.</p>

<p class="text-faded">One novel aspect of our program is a collaboration by our team on a proposal for a new data centric AI competition.  To help define Data Centric AI, the invited talks will mix research with case studies of data centric AI problems from industry, including startups (Landing AI and Snorkel AI) and large companies (Google and Facebook).  They will also highlight insights from the first generation of Data Centric AI competitions, including the winning submissions, the key insights, and invite the community to shape the future of Data Centric AI competitions.</p>  

                </p>
               
                <p class="text-faded">
                    We welcome <span style="color: white; font-weight: bold">short papers (1-2 pages)</span> and <span style="color: white; font-weight: bold">long papers (4 pages)</span> addressing one or more of the topics of interest below. Papers will be peer-reviewed by the program committee and accepted papers will be presented as lightning talks during the workshop.
                </p>
                <p class="text-center">
                    <br>
                    <a href="https://easychair.org/conferences/?conf=dew2020" target="_blank" class="btn btn-default btn-xl">Submission Link</a>
                </p>
                <br>
                <br>
                <h3 class="section-heading text-center" id="topics">Topics of Interest</h3>
                <hr class="primary">
                <p class="text-faded">
           We invite scientific contributions and positions papers on the following topics:

                    <p class="text-faded"><span style="color: white; font-weight: bold">New Datasets</span>:  in areas that align with MLCommons:
                    <ul class="text-faded">
                      <li>Speech, medical, recommendation/personalization</li>
                      <li>Science: <a href="https://www.mgi.gov/" target="_blank" style="color:while">https://www.mgi.gov/</a></li></ul>     </p> 
                   
                   <p class="text-faded"><span style="color: white; font-weight: bold">Tools & methodologies </span>for accelerating open-source dataset development:
		<ul class="text-faded">
                      <li>Tools that quantify and accelerate time to source and prepare high quality data</li>
			<li>Tools that ensure that the data is labeled consistently, such as label consensus</li>
			    <li>Tools that make improving data quality more systematic</li>
<li>Tools that automate the creation of high quality supervised learning training data from low quality resources, such as forced alignment in speech recognition</li>
<li>Tools that produce consistent and low noise data samples, or remove labeling noise or inconsistencies from existing data</li>
<li>Tools for controlling what goes into the dataset and for making high level edits efficiently to very large datasets, e.g. adding new words, languages, or accents to speech datasets with thousands of hours</li>
	    <li>Search methods for finding suitably licensed datasets based on public resources </li>
<li>Tools for creating training datasets for small data problems, or for rare classes in the long tail of big data problems </li>
<li>Tools for timely incorporation of feedback from production systems into datasets</li>
<li>Tools for understanding dataset coverage of important classes, and editing them to cover newly identified important cases</li>
<li>Dataset importers that allow easy combination and composition of existing datasets</li>
<li>Dataset exporters that make the data consumable for models and interface with model training and inference systems such as webdataset.</li>
<li>System architectures and interfaces that enable composition of dataset tools such as, MLCube, Docker, Airflow</li>

                    </ul>
                    </p>

                    <p class="text-faded"><span style="color: white; font-weight: bold">Algorithms</span> for working with limited labeled data and improving label efficiency:
                    <ul class="text-faded">
			    <li>Active learning</li>
<li>Semi-supervised learning</li>
<li>Self-supervised learning</li>
<li>Weak supervision</li>
<li>Few-shot / zero-shot learning</li>
<li>Transfer learning</li>
<li>Novelty detection</li>
<li>Drift detection</li>
                    </ul>
                    </p>

                    <p class="text-faded"><span style="color: white; font-weight: bold">Responsible AI development
:</span>
                    <ul class="text-faded">
                      <li>Fairness, bias, diversity evaluation and analysis for data sets and modeling/algorithms</li>
<li>Tools for green AI hardware-software system design and evaluation</li> 
<li>Scalable, reliable training methods and systems</li>
<li>Tools, methodologies, and techniques for private, secure machine learning training</li>
<li>Efforts toward reproducible AI, such as data cards, model cards</li>
                    </ul>
                    </p>

                    
                </p>
            </div>
        </div>
    </div>
</section>

  <section id="organizers">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h2 class="section-heading">Organizing Committee</h2>
                <hr class="light">
                <p>
<ul><li> Andrew Ng, Landing AI</li>
<li>Lora Aroyo, Google Research</li>
<li>Cody Coleman, Stanford University</li>
<li>Greg Diamos, Landing AI</li>
<li>Vijay Janapa Reddi, Harvard University</li>		    
<li>Joaquin Vanschoren, Eindhoven University of Technology</li>		    
<li>Sharon Zhou, Stanford University</li>		    
                </p>
                <br>
                <br>
                <h2 class="section-heading">Program Committee</h2>
                <hr class="light">
                <p>
                    TDB
                </p>
            </div>
        </div>
    </div>
</section>

  <section class="bg-primary" style="padding-bottom: 0" id="program">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2 class="section-heading text-center">Program</h2>
                <hr class="primary">
                <p>
                    <h3 class="text-center">Schedule</h3>
                    <br>
                    <table class="table table-striped text-center" style="font-size: 120%">
                        <thead style="font-weight: bold">
                            <tr>
                                <td>PT</td>
                                <td>EST</td>
                                <td>CET</td>
                                <td width="50%">Agenda</td>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>6:00 AM</td>
                                <td>9:00 AM</td>
                                <td>2:00 PM</td>
                                <td>Intro</td>
                            </tr>
                            <tr>
                                <td>6:10 AM</td>
                                <td>9:10 AM</td>
                                <td>2:10 PM</td>
                                <td><b>Invited talk: <a href="#ben-hutchinson" class="page-scroll" style="color: white; text-decoration: underline">Ben Hutchinson</a></b></td>
                            </tr>
                            <tr>
                                <td>6:30 AM</td>
                                <td>9:30 AM</td>
                                <td>2:30 PM</td>
                                <td><b>Invited talk: <a href="#ian-soboroff" class="page-scroll" style="color: white; text-decoration: underline">Ian Soboroff</a></b></td>
                            </tr>
                            <tr>
                                <td>6:50 AM</td>
                                <td>9:50 AM</td>
                                <td>2:50 PM</td>
                                <td><b>Invited talk: <a href="#andrea-olgiati" class="page-scroll" style="color: white; text-decoration: underline">Andrea Olgiati</a></b></td>
                            </tr>
                            <tr>
                                <td>7:10 AM</td>
                                <td>10:10 AM</td>
                                <td>3:10 PM</td>
                                <td>3x Lightning Talks</td>
                            </tr>
                            <tr>
                                <td>7:25 AM</td>
                                <td>10:25 AM</td>
                                <td>3:25 PM</td>
                                <td>Short Break</td>
                            </tr>
                            <tr>
                                <td>7:35 AM</td>
                                <td>10:35 AM</td>
                                <td>3:35 PM</td>
                                <td>Talks Discussion</td>
                            </tr>
                            <tr>
                                <td>8:05 AM</td>
                                <td>11:05 AM</td>
                                <td>4:05 PM</td>
                                <td><b>Invited talk: <a href="#emily-dinan" class="page-scroll" style="color: white; text-decoration: underline">Emily Dinan</a></b></td>
                            </tr>
                            <tr>
                                <td>8:25 AM</td>
                                <td>11:25 AM</td>
                                <td>4:25 PM</td>
                                <td><b>Invited talk: <a href="#aleksander-madry" class="page-scroll" style="color: white; text-decoration: underline">Aleksander Madry</a></b></td>
                            </tr>
                            <tr>
                                <td>8:45 AM</td>
                                <td>11:45 PM</td>
                                <td>4:45 PM</td>
                                <td>Short Break</td>
                            </tr>
                            <tr>
                                <td>8:55 AM</td>
                                <td>11:55 AM</td>
                                <td>4:55 PM</td>
                                <td><b>Invited talk: <a href="#quang-duong" class="page-scroll" style="color: white; text-decoration: underline">Quang Duong</a></b></td>
                            </tr>
                            <tr>
                                <td>9:15 AM</td>
                                <td>12:15 PM</td>
                                <td>5:15 PM</td>
                                <td><b>Invited talk: <a href="#peter-hallinan" class="page-scroll" style="color: white; text-decoration: underline">Peter Hallinan</a></b></td>
                            </tr>
                            <tr>
                                <td>9:35 AM</td>
                                <td>12:35 PM</td>
                                <td>5:35 PM</td>
                                <td>Talks Discussion</td>
                            </tr>
                            <tr>
                                <td>10:05 AM</td>
                                <td>1:05 PM</td>
                                <td>6:05 PM</td>
                                <td>Wrap Up</td>
                            </tr>
                            <tr>
                                <td>10:20 AM</td>
                                <td>1:20 PM</td>
                                <td>6:20 PM</td>
                                <td>End of Workshop</td>
                            </tr>
                        </tbody>
                    </table>
                </p>
                <br>
                <h3 id="papers" class="text-center">Accepted Papers</h3><br>
                <ul style="font-size: 120%; color: white">
                    <li><a href="http://eval.how/dew2020/submissions/DEW2020_paper_1%20(1).pdf" style="color: white" target="_blank"><b>Reducing Annotation Artifacts in Crowdsourcing Datasets for Natural Language Processing</b></a><br><i>Donghoon Han, Juho Kim and Alice Oh</i><br><br></li>
                    <li><a href="http://eval.how/dew2020/submissions/DEW2020_paper_2%20(1).pdf" style="color: white" target="_blank"><b>Machine Learning Training to Support Diversity of Opinion</b></a><br><i>Johanne Christensen and Benjamin Watson</i><br><br></li>
	    	    <li><a href="http://eval.how/dew2020/submissions/DEW2020_paper_3%20(1).pdf" style="color: white" target="_blank"><b>Data Desiderata: Reliability and Fidelity in High-stakes AI</b></a><br><i>Shivani Kapania, Nithya Sambasivan, Kristen Olson, Hannah Highfill, Diana Akrong, Praveen Paritosh and Lora Aroyo</i><br><br></li>
                </ul>
                <br>
                <h3 id="invited-talks" class="text-center">Invited Talks</h3><br>
            </div>
        </div>
    </div>
    <div class="container-fluid">
        <div class="row no-gutter">
            <div class="col-lg-3 col-sm-4">
                <a href="#emily-dinan" class="page-scroll portfolio-box">
                    <img src="img/keynotes/emily_dinan.jpg" class="img-responsive" alt="">
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-name">
                                Emily Dinan
                            </div>
                            <div class="project-category">
                                Facebook AI
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-lg-3 col-sm-4">
                <a href="#ian-soboroff" class="page-scroll portfolio-box">
                    <img src="img/keynotes/ian_soboroff.jpg" class="img-responsive" alt="">
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-name">
                                Ian Soboroff
                            </div>
                            <div class="project-category">
                                NIST
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-lg-3 col-sm-4">
                <a href="#aleksander-madry" class="page-scroll portfolio-box">
                    <img src="img/keynotes/aleksander_madry.jpg" class="img-responsive" alt="">
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-name">
                                Aleksander Mądry
                            </div>
                            <div class="project-category">
                                MIT
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-lg-3 col-sm-4">
                <a href="#quang-duong" class="page-scroll portfolio-box">
                    <img src="img/keynotes/quang_duong.jpg" class="img-responsive" alt="">
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-name">
                                Quang Duong
                            </div>
                            <div class="project-category">
                                Google Health
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-lg-3 col-sm-4">
                <a href="#andrea-olgiati" class="page-scroll portfolio-box">
                    <img src="img/keynotes/andrea_olgiati.jpg" class="img-responsive" alt="">
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-name">
                                Andrea Olgiati
                            </div>
                            <div class="project-category">
                                Amazon AI
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-lg-3 col-sm-4">
                <a href="#ben-hutchinson" class="page-scroll portfolio-box">
                    <img src="img/keynotes/ben_hutchinson.jpg" class="img-responsive" alt="">
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-name">
                                Ben Hutchinson
                            </div>
                            <div class="project-category">
                                Google Research
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="col-lg-3 col-sm-4">
                <a href="#peter-hallinan" class="page-scroll portfolio-box">
                    <img src="img/keynotes/peter_hallinan.jpg" class="img-responsive" alt="">
                    <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                            <div class="project-name">
                                Peter Hallinan
                            </div>
                            <div class="project-category">
                                Amazon
                            </div>
                        </div>
                    </div>
                </a>
            </div>
        </div>
    </div>
</section>
<section>
    <div class="container">
        <div class="row">
            <div id="aleksander-madry" class="col-lg-5 col-lg-offset-1" style="padding-right: 40px">
                <img src="img/keynotes/aleksander_madry.jpg" class="img-responsive" style="border-radius: 100%; width: 100%; height: auto; margin: 0 auto" alt="">
                <br>
                <h2 class="section-heading text-center"><a href="https://people.csail.mit.edu/madry/" target="_blank">Aleksander Madry (MIT)</a></h2>
                <hr class="primary">
                <h3 class="text-center">What Do Our Models Learn?</h3><br>
                <p>
                    Large-scale vision benchmarks have driven—and often even defined—progress in machine learning. However, these benchmarks are merely proxies for the real-world tasks we actually care about. How well do our benchmarks capture such tasks?
                    <br><br>
                    In this talk, I will discuss the alignment between our benchmark-driven ML paradigm and the real-world uses cases that motivate it. First, we will explore examples of biases in the ImageNet dataset, and how state-of-the-art models exploit them. We will then demonstrate how these biases arise as a result of design choices in the data collection and curation processes.
                    <br><br>
                    Throughout, we illustrate how one can leverage relatively standard tools (e.g., crowdsourcing, image processing) to quantify the biases that we observe.
                    <br><br>
                    Based on joint works with Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Jacob Steinhardt, Dimitris Tsipras and Kai Xiao.
                </p>
                <hr class="primary">
                <h3 class="text-center">Bio</h3><br>
                <p>
                    Aleksander Madry is a Professor of Computer Science in the MIT EECS Department and a Principal Investigator in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). He received his PhD from MIT in 2011 and, prior to joining the MIT faculty, he spent some time at Microsoft Research New England and on the faculty of EPFL.
                    <br><br>
                    Aleksander's research interests span algorithms, continuous optimization, science of deep learning, and understanding machine learning from a robustness and deployability perspectives. His work has been recognized with a number of awards, including an NSF CAREER Award, an Alfred P. Sloan Research Fellowship, an ACM Doctoral Dissertation Award Honorable Mention, and Presburger Award.
                </p>
            </div>
            <div id="emily-dinan" class="col-lg-5" style="padding-left: 40px">
                <img src="img/keynotes/emily_dinan.jpg" class="img-responsive" style="border-radius: 100%; width: 100%; height: auto; margin: 0 auto" alt="">
                <br>
                <h2 class="section-heading text-center"><a href="https://www.linkedin.com/in/emily-d-4553b9194/" target="_blank">Emily Dinan (Facebook AI)</a></h2>
                <hr class="primary">
                <h3 class="text-center">Adversarial Data Collection for Chatbot Safety</h3><br>
                <p>
                    Models trained on large unlabeled corpora of human interactions will learn patterns and mimic behaviors therein, which may include offensive or otherwise toxic behavior and unwanted biases. I will discuss several methods for mitigating these issues in neural dialogue models. In particular, I will highlight the use of iterative, adversarial human-and-model-in-the-loop data collection and model training procedures for the purpose of making chatbots robust to adversarial attack from humans. In opposition to static benchmarks, these approaches yield a “moving goalpost” for natural language understanding systems, and recent work shows that models trained on these increasingly complex tasks are more robust to adversarial attack.
                </p>
                <hr class="primary">
                <h3 class="text-center">Bio</h3><br>
                <p>
                    Emily is a Research Engineer at Facebook AI Research in New York. She graduated with a Master's degree in Mathematics from the University of Washington. Emily's research interests include conversational AI, natural language processing, and fairness in these fields.
                </p>
            </div>
        </div>
    </div>
</section>
<section class="bg-primary">
    <div class="container">
        <div class="row">
            <div id="ian-soboroff" class="col-lg-5 col-lg-offset-1" style="padding-right: 40px">
                <img src="img/keynotes/ian_soboroff.jpg" class="img-responsive" style="border-radius: 100%; width: 100%; height: auto; margin: 0 auto" alt="">
                <br>
                <h2 class="section-heading text-center"><a href="https://www.nist.gov/people/ian-soboroff" target="_blank" style="color: white">Ian Soboroff (NIST)</a></h2>
                <hr class="light">
                <h3 class="text-center">TREC: Building datasets within a community of use</h3><br>
                <p>
                    NIST's Text Retrieval Conference (TREC) and TRECVID evaluations of multimedia search are long-running evaluation workshops that develop datasets for search ranking, classification, and other AI tasks, along with appropriate metrics that the research community can use to gauge progress in those tasks.  Since the start of TREC in 1991, NIST has developed a large store of practical experience in collecting, assembling, labeling, and measuring the quality of datasets.  In this brief talk, I will describe the history of TREC relevance assessments, the processes we use to do determine those labels, and research on how to make those processes more robust, reliable, and inexpensive.
                </p>
                <hr class="primary">
                <h3 class="text-center">Bio</h3><br>
                <p>
                    Dr. Ian Soboroff is a computer scientist and leader of the Retrieval Group at the National Institute of Standards and Technology (NIST). The Retrieval Group organizes the Text REtrieval Conference (TREC), the Text Analysis Conference (TAC), and the TREC Video Retrieval Evaluation (TRECVID). These are all large, community-based research workshops that drive the state-of-the-art in information retrieval, video search, web search, information extraction, text summarization and other areas of information access. He has co-authored many publications in information retrieval evaluation, test collection building, text filtering, collaborative filtering, and intelligent software agents. His current research interests include building test collections for complex information seeking tasks.
                </p>
            </div>
            <div id="quang-duong" class="col-lg-5" style="padding-left: 40px">
                <img src="img/keynotes/quang_duong.jpg" class="img-responsive" style="border-radius: 100%; width: 100%; height: auto; margin: 0 auto" alt="">
                <br>
                <h2 class="section-heading text-center"><a href="https://www.linkedin.com/in/quang-duong-6667774/" target="_blank" style="color: white">Quang Duong (Google Health)</a></h2>
                <hr class="light">
                <h3 class="text-center">Asynchronous adjudication in labeling medical data: lessons, improvements and expansions</h3><br>
                <p>
                    Crowdsourcing has enabled the collection, aggregation and refinement of human knowledge and judgment, i.e. ground truth, for problem domains with data of increasing complexity and scale. A lack of comprehensive diagnostic reference standards in medicine significantly increases the complexity of labeling medical data. Asynchronous adjudication, a newly introduced method of facilitating asynchronous discussions among remote healthcare professionals, has enabled the generation of such ground truth, i.e. medical diagnoses,  with high quality at scale, and consequently, the development of machine learning based medical applications. 
                    <br><br>
                    In this talk, I will present the challenges of managing labellers, who often are medical experts, involved in asynchronously adjudicating medical labels. The discussion will focus on what information labellers find important to doing their jobs efficiently, and how such information impacts their work’s speed and quality. I next propose improvements to the current asynchronous adjudication mechanism. Last, I will describe a novel patented async adjudication expansion, designed and built to address the challenges of resolving disagreements among experts on visual annotations of medical images.
                </p>
                <hr class="primary">
                <h3 class="text-center">Bio</h3><br>
                <p>
                    I received my Ph.D.in Computer Science and Engineering from the University of Michigan, Artificial Intelligence Lab. From 2014 to 2018, I led and managed a data quality team of engineers and data scientists at Google Maps, responsible for building machine learning time-series models that detect and predict visit patterns useful in assisting users to plan their trips efficiently. We built innovative location-based systems for crowdsourcing users’ assessment about their physical surroundings in real time.  Since 2018, I have been leading a team tasked with developing a crowd-sourcing platform for medical labeling and diagnoses in Health, a new healthcare division at Google. The platform's output of high quality labeled data, generated securely and reliably at scale, is imperative to Google Health's efforts in building and deploying state-of-the-art machine-learning-powered diagnostic solutions, including ML models for diabetic retinopathy and breast cancer detection.
                </p>
            </div>
        </div>
    </div>
</section>
<section>
    <div class="container">
        <div class="row">
            <div id="andrea-olgiati" class="col-lg-5 col-lg-offset-1" style="padding-right: 40px">
                <img src="img/keynotes/andrea_olgiati.jpg" class="img-responsive" style="border-radius: 100%; width: 100%; height: auto; margin: 0 auto" alt="">
                <br>
                <h2 class="section-heading text-center"><a href="https://www.linkedin.com/in/andreaolgiati/" target="_blank">Andrea Olgiati (Amazon AI)</a></h2>
                <hr class="primary">
                <h3 class="text-center">Data =? Software</h3><br>
                <p>
                    Managing large amounts of data in a rigorous way is key to the success of ML initiatives. Yet, we still find that many organizations often do not have a complete view of their data, leading to sub-optimal and biased solutions. What can we learn from the world of software development to build a better-controlled system? How can the creation of controlled datasets become less of an art and more of a science?
                </p>
                <hr class="primary">
                <h3 class="text-center">Bio</h3><br>
                <p>
                    Andrea is a Senior Principal Engineer at AWS, where he is the technical leader for the AWS SageMaker managed ML platform. In the past he has worked on computer vision, databases and chip design. He holds a Laurea degree from Politecnico di Milano in Italy.
                </p>
            </div>
            <div id="peter-hallinan" class="col-lg-5" style="padding-left: 40px">
                <img src="img/keynotes/peter_hallinan.jpg" class="img-responsive" style="border-radius: 100%; width: 100%; height: auto; margin: 0 auto" alt="">
                <br>
                <h2 class="section-heading text-center"><a href="https://www.linkedin.com/in/pwhallinan/" target="_blank">Peter Hallinan (AI & Data @ Amazon)</a></h2>
                <hr class="primary">
                <h3 class="text-center">Getting good data faster</h3><br>
                <p>
                    The AI industry is collectively fielding tens of thousands of ML applications, many of which require human-labeled data (HLD) for training, evaluation or production “patching”. We identify business and operational challenges to producing high-quality HLD at scale, and review the pros and cons of common organizational solutions: outsourcing HLD to third-party vendors, insourcing HLD to a product or engineering sub-team, insourcing HLD to a specialized HLD function, letting science contributors fend for themselves, and hybrids of these.
                </p>
                <hr class="primary">
                <h3 class="text-center">Bio</h3><br>
                <p>
                    Peter W. Hallinan leads ML initiatives in human-labeled data at Amazon. Prior to Amazon, he was a partner at Blindsight (computer vision for the blind, sold to AMZN), and at Techcelerator, a venture development firm. Earlier, he was a vice president at Analysis Group / Integral, where he specialized in growth strategy and the management of innovation for Fortune 500 companies in high-tech, life science, and finance.  He holds A.B., S.M., and Ph.D. degrees from Harvard University, where he conducted research in pattern recognition and artificial intelligence, co-authored an early book on face recognition, and moonlighted as a teaching fellow in policy analysis and experimental design at the John F. Kennedy School of Government. His volunteer activities have included serving as a consulting professor at the Stanford School of Medicine, and leading the American Chamber of Commerce in Madagascar.
                </p>
            </div>
        </div>
    </div>
</section>
<section class="bg-primary">
    <div class="container">
        <div class="row">
            <div id="ben-hutchinson" class="col-lg-5 col-lg-offset-1" style="padding-right: 40px">
                <img src="img/keynotes/ben_hutchinson.jpg" class="img-responsive" style="border-radius: 100%; width: 100%; height: auto; margin: 0 auto" alt="">
                <br>
                <h2 class="section-heading text-center"><a href="https://www.linkedin.com/in/ben-hutchinson-ab56464/" target="_blank" style="color: white">Ben Hutchingson (Google Research)</a></h2>
                <hr class="light">
                <h3 class="text-center">Towards Accountability for Machine Learning Datasets: Lessons from Software Engineering</h3><br>
                <p>
                    Rising concern for the societal implications of artificial intelligence systems has inspired demands for greater transparency and accountability. However the datasets which empower machine learning are often used, shared and re-used with little visibility into the processes of deliberation which led to their creation. In this talk, I introduce a rigorous framework for dataset development transparency which supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields a set of documents that facilitate improved communication and decision-making, as well as drawing attention to the value and necessity of careful data work. The proposed framework is intended to contribute to closing the accountability gap in artificial intelligence systems, by making visible the often overlooked work that goes into dataset creation.
                </p>
                <hr class="primary">
                <h3 class="text-center">Bio</h3><br>
                <p>
                    Ben Hutchinson is a Senior Engineer in Google Research, working on artificial intelligence, dataset development practices, data ethics, fairness, and accountability. His research focuses on incorporating knowledge and practices from a variety of engineering and social science disciplines in order to inform the ethical development of AI. Prior to joining Google Research, he spent ten years writing code for a variety of products such as Google Maps, Knowledge Graph, and Google Search. He uses this engineering experience to help bridge the gaps between research and engineering, and between theory and practice.
                </p>
            </div>
        </div>
    </div>
</section>

  <section id="contact">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h2 class="section-heading">Contact</h2>
                <hr class="primary">
            </div>
        </div>
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <a href="mailto:data-excellence@googlegroups.com">
                <i class="fa fa-envelope-o fa-3x wow bounceIn" data-wow-delay=".1s"></i>
                    <p>data-excellence@googlegroups.com</p>
                </a>
            </div>
        </div>
    </div>
</section>

  <!-- jQuery -->
<script src="js/jquery.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="js/bootstrap.min.js"></script>

<!-- Plugin JavaScript -->
<script src="js/jquery.easing.min.js"></script>
<script src="js/jquery.fittext.js"></script>
<script src="js/wow.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="js/creative.js"></script>

</body>

</html>
