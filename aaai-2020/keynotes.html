<!DOCTYPE html>

<html>	
<title> Evaluating Evaluation of AI Systems (Meta-Eval 2020) </title>

<body bgcolor="ffffff" style = "font-family:arial;font-size:14px;font-style:normal;">
  
<h1>Evaluating Evaluation of AI Systems (Meta-Eval 2020)</h1>
<p>Workshop at <a href=https://aaai.org/Conferences/AAAI-20/> The thirty fourth AAAI Conference on Artificial Intelligence </a></p>
<p><b>Date:</b> 8 Feb 2020 </p>
<p><b>Location:</b> Hilton New York Midtown (Conference Venue)</p>
<p><b> <a href=http://eval.how/aaai-2020/> Workshop Website</a></b></p>

<h2> Keynote Speakers </h2>
<h3> <a href=https://www.cs.uml.edu/~arogers/>Anna Rogers</a></h3>
<p><img src="anna_rogers.jpg" alt="Anna Rogers IMG" style="width:100px;height:130px;"></p>
<ul>
<li> <b>Title:</b> The questions that the current AI can't answer. </li>
<li> <b>Abstract:</b> NLP is witnessing an explosion of question answering datasets, most of which get "solved" within months of publication. However, that does not necessarily mean that we are making fast progress towards machine language understanding. I discuss the current proposals for making the datasets more difficult, and the ways in which the current deep learning models "cheat", avoiding the complex verbal reasoning we expect them to perform.</li>
<li> <b>Bio:</b> Anna Rogers is a post-doctoral associate at University of Massachusetts (Lowell). Her research focuses on representation learning, natural language understanding, evaluation methodology for NLP, and computational social science. </li>
</ul>

<h3> <a href=https://www.ntnu.edu/employees/odderik> Odd Erik Gunderson </a></h3>
<p><img src="odderik.jpg" alt="Odd Erik Gunderson IMG" style="width:130px;height:130px;"></p>

<ul>
<li> <b>Title:</b> Reproducibility in AI </li>
</ul>

<h3> <a href=https://aws.amazon.com/augmented-ai/> Sam Henry, Senior SDM, Amazon Augmented AI (Amazon A2I)</a></h3>
<ul>
<li> <b>Title:</b> People + AI = Magic </li>
<li> <b>Abstract:</b> We will share new innovations in machine learning accuracy and the importance of maintaining people in the loop for AI applications. Many machine learning solutions require humans to review low confidence inference for accuracy, audit or compliance. We will demonstrate new mechanisms for bringing nuanced human inputs into the ML workflow which will enable sectors which had previously relied solely on humans or could not use ML at all.</li>
<li> <b>Bio:</b> AWS A2I is an organization within the AI/ML division of AWS that is focused on accelerating ML deployment and improving model accuracy. </li>
</ul>



<h2>Contact Organizing Committee </h2>
Email: rigorous-evaluation AT googlegroups.com
</body>
</html>
